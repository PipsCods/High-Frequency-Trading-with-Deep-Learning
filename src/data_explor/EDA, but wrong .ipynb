{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "from pmdarima import auto_arima\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"EDA\"))\n",
    "from EDA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "DATA_PATH = '../../data/high_10m.parquet'\n",
    "NUM_LAGS = 10\n",
    "NUM_STOCKS = 10\n",
    "TRAIN_WINDOW = 50\n",
    "OUTPUT_PATH = '../../data/processed_high_10m_subset.parquet'\n",
    "SEED = 42\n",
    "SHRINKAGE_LIST = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df.head()\n",
    "\n",
    "df = df[df['RETURN_NoOVERNIGHT'] != 0]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### 1. Comparison of linear returns vs log returns\n",
    "- Description\n",
    "- Plot the density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_series(df[\"RETURN_NoOVERNIGHT\"])\n",
    "describe_series(df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_density_logvslin(df[\"RETURN_NoOVERNIGHT\"], df[\"LOG_RETURN_NoOVERNIGHT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Both aggregated linear and log returns look normal distributed, with log returns showing the additional benefit of smoothing out the extreme tails.\n",
    "From this moment foward, we consider in our analysis only log returns. \n",
    "#### 2. Outliners analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_violin(df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_ecdf(df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_qq(df[\"LOG_RETURN_NoOVERNIGHT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorized Dataframe\n",
    "winsorized_df = select_winsorized(df, column= 'LOG_RETURN_NoOVERNIGHT', lower_percentile=0.01, upper_percentile= 0.99)\n",
    "describe_series(winsorized_df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_histogram_distribution(winsorized_df[\"LOG_RETURN_NoOVERNIGHT\"], n_bins=500, left_limit = -0.01, right_limit = 0.01)\n",
    "plot_boxplot(winsorized_df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_violin(winsorized_df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_ecdf(winsorized_df[\"LOG_RETURN_NoOVERNIGHT\"])\n",
    "plot_qq(winsorized_df[\"LOG_RETURN_NoOVERNIGHT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### 3. Correlation and dependence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorized_df['DATETIME'] = pd.to_datetime(winsorized_df['DATE'].astype(str) + ' ' + df['TIME'].astype(str))\n",
    "\n",
    "returns_pivot = winsorized_df.pivot_table(index='DATETIME', columns='SYMBOL', values='LOG_RETURN_NoOVERNIGHT', aggfunc='mean')\n",
    "distribution_correlation(returns_pivot)\n",
    "\n",
    "#TODO: not sure what the y axis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Check stationarity, autocorrelation, and partial autocorrelation in automatic way, choosing the best ARIMA parameters\n",
    "# ARIMA model is used fir each stock symbol and the results are stored in a DataFrame\n",
    "\n",
    "results = []\n",
    "\n",
    "for symbol, group in winsorized_df.groupby('SYMBOL'):\n",
    "    group = group.sort_index()\n",
    "    series = group['LOG_RETURN_NoOVERNIGHT'].dropna()\n",
    "\n",
    "    if len(series) < 20:\n",
    "        continue\n",
    "\n",
    "    # Create train/test split\n",
    "    split = int(len(series) * 0.9)\n",
    "    train, test = series[:split], series[split:]\n",
    "\n",
    "    try:\n",
    "        # Workaround: convert series to array but preserve date index externally\n",
    "        model = auto_arima(train.values, seasonal=False, suppress_warnings=True, stepwise=True)\n",
    "\n",
    "        forecast = model.predict(n_periods=len(test))\n",
    "\n",
    "        mse = mean_squared_error(test.values, forecast)\n",
    "\n",
    "        results.append({\n",
    "            'symbol': symbol,\n",
    "            'order': model.order,\n",
    "            'aic': model.aic(),\n",
    "            'bic': model.bic(),\n",
    "            'mse': mse,\n",
    "            'train_len': len(train),\n",
    "            'test_len': len(test)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{symbol}: ARIMA failed - {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_garch_volatility(df, return_col='LOG_RETURN_NoOVERNIGHT'):\n",
    "    df = df.copy()\n",
    "    df['GARCH_VOL'] = None  # Placeholder for volatility\n",
    "\n",
    "    # Group by stock symbol\n",
    "    grouped = df.groupby('SYMBOL')\n",
    "\n",
    "    all_vols = []\n",
    "\n",
    "    for symbol, group in tqdm(grouped, desc='Fitting GARCH'):\n",
    "        group = group.sort_index()\n",
    "        returns = group[return_col].dropna()\n",
    "\n",
    "        # Fit only if enough data\n",
    "        if len(returns) < 50:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Fit GARCH(1,1)\n",
    "            model = arch_model(returns, vol='GARCH', p=1, q=1)\n",
    "            result = model.fit(disp='off')\n",
    "\n",
    "            # Extract conditional volatility\n",
    "            vol = result.conditional_volatility\n",
    "            vol_df = vol.to_frame(name='GARCH_VOL')\n",
    "            vol_df['SYMBOL'] = symbol\n",
    "            vol_df['DATETIME'] = vol_df.index\n",
    "\n",
    "            all_vols.append(vol_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"GARCH failed for {symbol}: {e}\")\n",
    "\n",
    "    # Merge GARCH volatility back to main df\n",
    "    if all_vols:\n",
    "        garch_df = pd.concat(all_vols)\n",
    "        df = df.merge(garch_df, on=['SYMBOL', 'DATETIME'], how='left', suffixes=('', '_GARCH'))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Your original returns DataFrame (with DATETIME index or column)\n",
    "df['DATETIME'] = pd.to_datetime(df['DATETIME'])\n",
    "\n",
    "# Call the function\n",
    "df_with_vol = add_garch_volatility(df, return_col='LOG_RETURN_NoOVERNIGHT')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
